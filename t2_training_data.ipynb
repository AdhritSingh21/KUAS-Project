{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, BatchNormalization\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statistics import pstdev, mean\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CGM</th>\n",
       "      <th>CGM_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-03 14:30:00</th>\n",
       "      <td>131.4</td>\n",
       "      <td>125.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-03 15:00:00</th>\n",
       "      <td>125.1</td>\n",
       "      <td>120.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-03 15:30:00</th>\n",
       "      <td>120.6</td>\n",
       "      <td>117.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-03 16:00:00</th>\n",
       "      <td>117.9</td>\n",
       "      <td>129.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-03 16:30:00</th>\n",
       "      <td>129.6</td>\n",
       "      <td>136.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CGM  CGM_predict\n",
       "Time                                   \n",
       "2021-02-03 14:30:00  131.4        125.1\n",
       "2021-02-03 15:00:00  125.1        120.6\n",
       "2021-02-03 15:30:00  120.6        117.9\n",
       "2021-02-03 16:00:00  117.9        129.6\n",
       "2021-02-03 16:30:00  129.6        136.8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data/visualize\n",
    "file_path = r'C:\\Users\\19176\\Desktop\\Ohio Data Set\\data\\t2_diabetes\\t2_cleaned_training_folder\\cleaned_2015_0_20210203.csv'\n",
    "data = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# Display the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_lstm_cgm(X_train, y_train):\n",
    "    n_folds = 5\n",
    "    cross_validation = KFold(n_folds)\n",
    "\n",
    "    X_data = X_train\n",
    "    y_data = y_train\n",
    "    # input_dim = X_data.shape[1]\n",
    "    scaler_x = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_x.fit(X_data)\n",
    "    scaler_y.fit(y_data)\n",
    "    scaled_X_train_data = scaler_x.transform(X_data)\n",
    "    scaled_y_train_data = scaler_y.transform(y_data)\n",
    "    scaled_X_train_data = np.reshape(scaled_X_train_data, (scaled_X_train_data.shape[0], 1, scaled_X_train_data.shape[1]))\n",
    "\n",
    "    lstm_best_score = []\n",
    "    model_check_point_callback = keras.callbacks.ModelCheckpoint(\n",
    "        filepath = 't2_lstm_cgm.h5',\n",
    "        save_best_only = True,\n",
    "        monitor = 'val_loss')\n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience=100)\n",
    "\n",
    "    for train_id_x, val_id_x in cross_validation.split(scaled_X_train_data, scaled_y_train_data):\n",
    "        X_train_fold, X_val_fold = scaled_X_train_data[train_id_x], scaled_X_train_data[val_id_x]\n",
    "        y_train_fold, y_val_fold = scaled_y_train_data[train_id_x], scaled_y_train_data[val_id_x]\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(128, input_shape = (scaled_X_train_data.shape[1], scaled_X_train_data.shape[2])))\n",
    "        model.add(Dense(150, activation = 'relu'))\n",
    "        model.add(Dropout(0.20))\n",
    "        model.add(Dense(100, activation = 'relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "        model.add(Dense(50, activation = 'relu'))\n",
    "        model.add(Dense(20, activation = 'relu'))\n",
    "        model.add(Dense(1, activation = 'relu'))\n",
    "        model.compile(loss = 'mse', optimizer = 'adam')\n",
    "        model.summary()\n",
    "        model.fit(X_train_fold, y_train_fold,\n",
    "                  epochs = 200, batch_size = 32, shuffle = False,\n",
    "                  verbose=1,\n",
    "                  validation_data = (X_val_fold, y_val_fold),\n",
    "                  callbacks = [early_stopping, model_check_point_callback])\n",
    "        lstm_best_score.append(model_check_point_callback.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       CGM\n",
      "Time                      \n",
      "2021-02-03 14:30:00  131.4\n",
      "2021-02-03 15:00:00  125.1\n",
      "2021-02-03 15:30:00  120.6\n",
      "2021-02-03 16:00:00  117.9\n",
      "2021-02-03 16:30:00  129.6\n",
      "...                    ...\n",
      "2021-02-17 10:30:00  175.5\n",
      "2021-02-17 11:00:00  151.2\n",
      "2021-02-17 11:30:00  135.9\n",
      "2021-02-17 12:00:00  136.8\n",
      "2021-02-17 12:30:00  161.1\n",
      "\n",
      "[669 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.DataFrame(index = data.index, data = data.CGM, columns = ['CGM'])\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     CGM_predict\n",
      "Time                            \n",
      "2021-02-03 14:30:00        125.1\n",
      "2021-02-03 15:00:00        120.6\n",
      "2021-02-03 15:30:00        117.9\n",
      "2021-02-03 16:00:00        129.6\n",
      "2021-02-03 16:30:00        136.8\n",
      "...                          ...\n",
      "2021-02-17 10:30:00        151.2\n",
      "2021-02-17 11:00:00        135.9\n",
      "2021-02-17 11:30:00        136.8\n",
      "2021-02-17 12:00:00        161.1\n",
      "2021-02-17 12:30:00        183.6\n",
      "\n",
      "[669 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.DataFrame(index = data.index, data = data.CGM_predict, columns = ['CGM_predict'])\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 128)               66560     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 150)               19350     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,101\n",
      "Trainable params: 107,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 4s 60ms/step - loss: 0.1758 - val_loss: 0.0564\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0337 - val_loss: 0.0162\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0167\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0088\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0074\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0072\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0072\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0072\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0073\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 128)               66560     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 150)               19350     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,101\n",
      "Trainable params: 107,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 3s 46ms/step - loss: 0.1709 - val_loss: 0.1082\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0451 - val_loss: 0.0262\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0247 - val_loss: 0.0183\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0146\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.0071\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0075\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0079\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0084\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0085\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0077\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 128)               66560     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 150)               19350     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,101\n",
      "Trainable params: 107,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 4s 43ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.2098\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 128)               66560     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 150)               19350     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,101\n",
      "Trainable params: 107,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 3s 42ms/step - loss: 0.1208 - val_loss: 0.0458\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0241 - val_loss: 0.0277\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.0211\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0170\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0104\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0111\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0104\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0112\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0107\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0106\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0109\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0099\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0100\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0106\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0098\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0101\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0098\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0108\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0099\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0100\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0098\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0099\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0099\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0101\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0099\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0106\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0101\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0100\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0100\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0098\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0106\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0102\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0101\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0099\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0099\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0106\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0099\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0101\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0099\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0099\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0102\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0106\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0102\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 128)               66560     \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 150)               19350     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 150)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,101\n",
      "Trainable params: 107,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 3s 41ms/step - loss: 0.0728 - val_loss: 0.0373\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0281 - val_loss: 0.0110\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0076\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0054\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0056\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0054\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0053\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0053\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0053\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0054\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0053\n"
     ]
    }
   ],
   "source": [
    "train_model_lstm_cgm(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_root_mean_squared_error(true, pred):\n",
    "    squared_error = np.square((true - pred))\n",
    "    sum_squared_error = np.sum(squared_error)\n",
    "    rmse = np.sqrt(sum_squared_error / true.size)\n",
    "    nrmse_loss = round(rmse/np.std(true),3) # pred or true\n",
    "    return nrmse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_model(model, data, print_individual_metrics):\n",
    "    test_time = data.index\n",
    "    test_gl_value = data['CGM']\n",
    "    X_data = data.drop(columns = ['CGM_predict'])\n",
    "    y_data = data[['CGM_predict']]\n",
    "    input_dim = X_data.shape[1]\n",
    "\n",
    "    scaler_x = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_x.fit(X_data)\n",
    "    scaler_y.fit(y_data)\n",
    "\n",
    "    X_test_data = data.drop(columns = ['CGM_predict'])\n",
    "    y_test_data = data[['CGM_predict']]\n",
    "    scaled_X_test_data = scaler_x.transform(X_test_data)\n",
    "    scaled_X_test_data = np.reshape(scaled_X_test_data, (scaled_X_test_data.shape[0], 1, scaled_X_test_data.shape[1]))\n",
    "    prediction = model.predict(scaled_X_test_data, batch_size = 32)\n",
    "    scaled_prediction = scaler_y.inverse_transform(prediction)\n",
    "\n",
    "    mae = mean_absolute_error(scaled_prediction, y_test_data)\n",
    "    rmse = math.sqrt(mean_squared_error(scaled_prediction, y_test_data))\n",
    "    nrmse = normalized_root_mean_squared_error(scaled_prediction, y_test_data.values)\n",
    "\n",
    "    if print_individual_metrics == True:\n",
    "        print(f\"MAE: {round(mae,3)}\")\n",
    "        print(f\"RMSE: {round(rmse,3)}\")\n",
    "        print(f\"NRMSE: {round(nrmse,3)}\")\n",
    "\n",
    "    return (mae,\n",
    "            rmse,\n",
    "            nrmse,\n",
    "            y_test_data.values,\n",
    "            scaled_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 1ms/step\n",
      "MAE: 14.846\n",
      "RMSE: 20.647\n",
      "NRMSE: 0.554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14.846038752215145,\n",
       " 20.646938391941553,\n",
       " 0.554,\n",
       " array([[125.1],\n",
       "        [120.6],\n",
       "        [117.9],\n",
       "        [129.6],\n",
       "        [136.8],\n",
       "        [137.7],\n",
       "        [163.8],\n",
       "        [188.1],\n",
       "        [201.6],\n",
       "        [225.9],\n",
       "        [233.1],\n",
       "        [207.9],\n",
       "        [203.4],\n",
       "        [200.7],\n",
       "        [177.3],\n",
       "        [139.5],\n",
       "        [144.9],\n",
       "        [157.5],\n",
       "        [151.2],\n",
       "        [139.5],\n",
       "        [130.5],\n",
       "        [144.9],\n",
       "        [144.9],\n",
       "        [141.3],\n",
       "        [147.6],\n",
       "        [144. ],\n",
       "        [139.5],\n",
       "        [146.7],\n",
       "        [142.2],\n",
       "        [140.4],\n",
       "        [147.6],\n",
       "        [160.2],\n",
       "        [167.4],\n",
       "        [162. ],\n",
       "        [229.5],\n",
       "        [312.3],\n",
       "        [330.3],\n",
       "        [294.3],\n",
       "        [229.5],\n",
       "        [172.8],\n",
       "        [143.1],\n",
       "        [131.4],\n",
       "        [160.2],\n",
       "        [209.7],\n",
       "        [234. ],\n",
       "        [250.2],\n",
       "        [246.6],\n",
       "        [243. ],\n",
       "        [220.5],\n",
       "        [234.9],\n",
       "        [233.1],\n",
       "        [225.9],\n",
       "        [200.7],\n",
       "        [181.8],\n",
       "        [177.3],\n",
       "        [193.5],\n",
       "        [197.1],\n",
       "        [196.2],\n",
       "        [204.3],\n",
       "        [211.5],\n",
       "        [155.7],\n",
       "        [136.8],\n",
       "        [147.6],\n",
       "        [148.5],\n",
       "        [157.5],\n",
       "        [176.4],\n",
       "        [180.9],\n",
       "        [175.5],\n",
       "        [176.4],\n",
       "        [171. ],\n",
       "        [170.1],\n",
       "        [173.7],\n",
       "        [170.1],\n",
       "        [162. ],\n",
       "        [157.5],\n",
       "        [136.8],\n",
       "        [154.8],\n",
       "        [140.4],\n",
       "        [138.6],\n",
       "        [144. ],\n",
       "        [145.8],\n",
       "        [140.4],\n",
       "        [139.5],\n",
       "        [149.4],\n",
       "        [148.5],\n",
       "        [197.1],\n",
       "        [240.3],\n",
       "        [218.7],\n",
       "        [209.7],\n",
       "        [165.6],\n",
       "        [153. ],\n",
       "        [157.5],\n",
       "        [159.3],\n",
       "        [180.9],\n",
       "        [205.2],\n",
       "        [226.8],\n",
       "        [228.6],\n",
       "        [206.1],\n",
       "        [175.5],\n",
       "        [155.7],\n",
       "        [139.5],\n",
       "        [135. ],\n",
       "        [140.4],\n",
       "        [153.9],\n",
       "        [165.6],\n",
       "        [183.6],\n",
       "        [219.6],\n",
       "        [233.1],\n",
       "        [233.1],\n",
       "        [240.3],\n",
       "        [245.7],\n",
       "        [246.6],\n",
       "        [230.4],\n",
       "        [218.7],\n",
       "        [213.3],\n",
       "        [207.9],\n",
       "        [189. ],\n",
       "        [177.3],\n",
       "        [181.8],\n",
       "        [186.3],\n",
       "        [172.8],\n",
       "        [167.4],\n",
       "        [182.7],\n",
       "        [164.7],\n",
       "        [153.9],\n",
       "        [156.6],\n",
       "        [153.9],\n",
       "        [159.3],\n",
       "        [162.9],\n",
       "        [153. ],\n",
       "        [188.1],\n",
       "        [230.4],\n",
       "        [226.8],\n",
       "        [205.2],\n",
       "        [191.7],\n",
       "        [186.3],\n",
       "        [178.2],\n",
       "        [165.6],\n",
       "        [197.1],\n",
       "        [258.3],\n",
       "        [288.9],\n",
       "        [299.7],\n",
       "        [291.6],\n",
       "        [283.5],\n",
       "        [270.9],\n",
       "        [261.9],\n",
       "        [244.8],\n",
       "        [221.4],\n",
       "        [200.7],\n",
       "        [195.3],\n",
       "        [186.3],\n",
       "        [176.4],\n",
       "        [191.7],\n",
       "        [182.7],\n",
       "        [182.7],\n",
       "        [189. ],\n",
       "        [200.7],\n",
       "        [198.9],\n",
       "        [201.6],\n",
       "        [229.5],\n",
       "        [243.9],\n",
       "        [249.3],\n",
       "        [220.5],\n",
       "        [196.2],\n",
       "        [172.8],\n",
       "        [173.7],\n",
       "        [162.9],\n",
       "        [149.4],\n",
       "        [147.6],\n",
       "        [142.2],\n",
       "        [140.4],\n",
       "        [144. ],\n",
       "        [142.2],\n",
       "        [143.1],\n",
       "        [144.9],\n",
       "        [162.9],\n",
       "        [149.4],\n",
       "        [150.3],\n",
       "        [205.2],\n",
       "        [234.9],\n",
       "        [247.5],\n",
       "        [221.4],\n",
       "        [198.9],\n",
       "        [174.6],\n",
       "        [139.5],\n",
       "        [132.3],\n",
       "        [125.1],\n",
       "        [144.9],\n",
       "        [161.1],\n",
       "        [179.1],\n",
       "        [171. ],\n",
       "        [146.7],\n",
       "        [164.7],\n",
       "        [167.4],\n",
       "        [168.3],\n",
       "        [190.8],\n",
       "        [236.7],\n",
       "        [250.2],\n",
       "        [238.5],\n",
       "        [278.1],\n",
       "        [298.8],\n",
       "        [277.2],\n",
       "        [254.7],\n",
       "        [241.2],\n",
       "        [216.9],\n",
       "        [184.5],\n",
       "        [153. ],\n",
       "        [144. ],\n",
       "        [154.8],\n",
       "        [159.3],\n",
       "        [131.4],\n",
       "        [126.9],\n",
       "        [128.7],\n",
       "        [133.2],\n",
       "        [135.9],\n",
       "        [136.8],\n",
       "        [137.7],\n",
       "        [142.2],\n",
       "        [143.1],\n",
       "        [145.8],\n",
       "        [137.7],\n",
       "        [137.7],\n",
       "        [142.2],\n",
       "        [150.3],\n",
       "        [144. ],\n",
       "        [148.5],\n",
       "        [211.5],\n",
       "        [249.3],\n",
       "        [251.1],\n",
       "        [241.2],\n",
       "        [198.9],\n",
       "        [145.8],\n",
       "        [124.2],\n",
       "        [107.1],\n",
       "        [153. ],\n",
       "        [201.6],\n",
       "        [218.7],\n",
       "        [207. ],\n",
       "        [172.8],\n",
       "        [183.6],\n",
       "        [195.3],\n",
       "        [225. ],\n",
       "        [252.9],\n",
       "        [256.5],\n",
       "        [261. ],\n",
       "        [263.7],\n",
       "        [234. ],\n",
       "        [208.8],\n",
       "        [183.6],\n",
       "        [191.7],\n",
       "        [163.8],\n",
       "        [120.6],\n",
       "        [123.3],\n",
       "        [131.4],\n",
       "        [136.8],\n",
       "        [148.5],\n",
       "        [166.5],\n",
       "        [175.5],\n",
       "        [186.3],\n",
       "        [186.3],\n",
       "        [185.4],\n",
       "        [188.1],\n",
       "        [186.3],\n",
       "        [179.1],\n",
       "        [176.4],\n",
       "        [171. ],\n",
       "        [162.9],\n",
       "        [154.8],\n",
       "        [153.9],\n",
       "        [154.8],\n",
       "        [149.4],\n",
       "        [158.4],\n",
       "        [147.6],\n",
       "        [140.4],\n",
       "        [170.1],\n",
       "        [228.6],\n",
       "        [252. ],\n",
       "        [249.3],\n",
       "        [216.9],\n",
       "        [178.2],\n",
       "        [146.7],\n",
       "        [111.6],\n",
       "        [117.9],\n",
       "        [139.5],\n",
       "        [180.9],\n",
       "        [200.7],\n",
       "        [180. ],\n",
       "        [143.1],\n",
       "        [133.2],\n",
       "        [124.2],\n",
       "        [138.6],\n",
       "        [133.2],\n",
       "        [144. ],\n",
       "        [170.1],\n",
       "        [200.7],\n",
       "        [221.4],\n",
       "        [209.7],\n",
       "        [188.1],\n",
       "        [185.4],\n",
       "        [246.6],\n",
       "        [256.5],\n",
       "        [222.3],\n",
       "        [206.1],\n",
       "        [189. ],\n",
       "        [169.2],\n",
       "        [165.6],\n",
       "        [171. ],\n",
       "        [178.2],\n",
       "        [173.7],\n",
       "        [174.6],\n",
       "        [171.9],\n",
       "        [166.5],\n",
       "        [166.5],\n",
       "        [166.5],\n",
       "        [171.9],\n",
       "        [165.6],\n",
       "        [163.8],\n",
       "        [161.1],\n",
       "        [171. ],\n",
       "        [179.1],\n",
       "        [170.1],\n",
       "        [166.5],\n",
       "        [164.7],\n",
       "        [172.8],\n",
       "        [244.8],\n",
       "        [300.6],\n",
       "        [311.4],\n",
       "        [279.9],\n",
       "        [264.6],\n",
       "        [228.6],\n",
       "        [192.6],\n",
       "        [189.9],\n",
       "        [173.7],\n",
       "        [150.3],\n",
       "        [150.3],\n",
       "        [142.2],\n",
       "        [128.7],\n",
       "        [152.1],\n",
       "        [218.7],\n",
       "        [269.1],\n",
       "        [290.7],\n",
       "        [315. ],\n",
       "        [302.4],\n",
       "        [248.4],\n",
       "        [216.9],\n",
       "        [219.6],\n",
       "        [234. ],\n",
       "        [239.4],\n",
       "        [220.5],\n",
       "        [224.1],\n",
       "        [224.1],\n",
       "        [226.8],\n",
       "        [231.3],\n",
       "        [234.9],\n",
       "        [243.9],\n",
       "        [232.2],\n",
       "        [214.2],\n",
       "        [206.1],\n",
       "        [193.5],\n",
       "        [209.7],\n",
       "        [223.2],\n",
       "        [227.7],\n",
       "        [229.5],\n",
       "        [229.5],\n",
       "        [221.4],\n",
       "        [213.3],\n",
       "        [195.3],\n",
       "        [198. ],\n",
       "        [185.4],\n",
       "        [161.1],\n",
       "        [191.7],\n",
       "        [267.3],\n",
       "        [279.9],\n",
       "        [258.3],\n",
       "        [217.8],\n",
       "        [179.1],\n",
       "        [152.1],\n",
       "        [132.3],\n",
       "        [119.7],\n",
       "        [121.5],\n",
       "        [109.8],\n",
       "        [114.3],\n",
       "        [149.4],\n",
       "        [167.4],\n",
       "        [154.8],\n",
       "        [180. ],\n",
       "        [207. ],\n",
       "        [209.7],\n",
       "        [221.4],\n",
       "        [215.1],\n",
       "        [187.2],\n",
       "        [170.1],\n",
       "        [178.2],\n",
       "        [182.7],\n",
       "        [184.5],\n",
       "        [183.6],\n",
       "        [180.9],\n",
       "        [173.7],\n",
       "        [172.8],\n",
       "        [158.4],\n",
       "        [157.5],\n",
       "        [184.5],\n",
       "        [182.7],\n",
       "        [168.3],\n",
       "        [158.4],\n",
       "        [156.6],\n",
       "        [154.8],\n",
       "        [159.3],\n",
       "        [156.6],\n",
       "        [151.2],\n",
       "        [151.2],\n",
       "        [147.6],\n",
       "        [150.3],\n",
       "        [149.4],\n",
       "        [150.3],\n",
       "        [159.3],\n",
       "        [162. ],\n",
       "        [164.7],\n",
       "        [214.2],\n",
       "        [286.2],\n",
       "        [306. ],\n",
       "        [280.8],\n",
       "        [221.4],\n",
       "        [170.1],\n",
       "        [143.1],\n",
       "        [112.5],\n",
       "        [103.5],\n",
       "        [ 97.2],\n",
       "        [ 99.9],\n",
       "        [ 92.7],\n",
       "        [118.8],\n",
       "        [174.6],\n",
       "        [222.3],\n",
       "        [263.7],\n",
       "        [283.5],\n",
       "        [267.3],\n",
       "        [239.4],\n",
       "        [252. ],\n",
       "        [236.7],\n",
       "        [198. ],\n",
       "        [182.7],\n",
       "        [182.7],\n",
       "        [183.6],\n",
       "        [177.3],\n",
       "        [156.6],\n",
       "        [175.5],\n",
       "        [190.8],\n",
       "        [208.8],\n",
       "        [239.4],\n",
       "        [254.7],\n",
       "        [242.1],\n",
       "        [235.8],\n",
       "        [202.5],\n",
       "        [203.4],\n",
       "        [191.7],\n",
       "        [180.9],\n",
       "        [174.6],\n",
       "        [183.6],\n",
       "        [175.5],\n",
       "        [172.8],\n",
       "        [175.5],\n",
       "        [174.6],\n",
       "        [171. ],\n",
       "        [171. ],\n",
       "        [181.8],\n",
       "        [181.8],\n",
       "        [171.9],\n",
       "        [174.6],\n",
       "        [183.6],\n",
       "        [168.3],\n",
       "        [192.6],\n",
       "        [261.9],\n",
       "        [301.5],\n",
       "        [306.9],\n",
       "        [300.6],\n",
       "        [251.1],\n",
       "        [211.5],\n",
       "        [170.1],\n",
       "        [153. ],\n",
       "        [151.2],\n",
       "        [142.2],\n",
       "        [136.8],\n",
       "        [140.4],\n",
       "        [153. ],\n",
       "        [217.8],\n",
       "        [280.8],\n",
       "        [306.9],\n",
       "        [305.1],\n",
       "        [295.2],\n",
       "        [279. ],\n",
       "        [254.7],\n",
       "        [250.2],\n",
       "        [238.5],\n",
       "        [209.7],\n",
       "        [189. ],\n",
       "        [177.3],\n",
       "        [186.3],\n",
       "        [194.4],\n",
       "        [186.3],\n",
       "        [181.8],\n",
       "        [184.5],\n",
       "        [177.3],\n",
       "        [175.5],\n",
       "        [180. ],\n",
       "        [176.4],\n",
       "        [183.6],\n",
       "        [171. ],\n",
       "        [163.8],\n",
       "        [168.3],\n",
       "        [166.5],\n",
       "        [164.7],\n",
       "        [165.6],\n",
       "        [174.6],\n",
       "        [184.5],\n",
       "        [255.6],\n",
       "        [282.6],\n",
       "        [269.1],\n",
       "        [221.4],\n",
       "        [189. ],\n",
       "        [162.9],\n",
       "        [149.4],\n",
       "        [144. ],\n",
       "        [160.2],\n",
       "        [200.7],\n",
       "        [241.2],\n",
       "        [251.1],\n",
       "        [245.7],\n",
       "        [249.3],\n",
       "        [231.3],\n",
       "        [198. ],\n",
       "        [162.9],\n",
       "        [152.1],\n",
       "        [145.8],\n",
       "        [138.6],\n",
       "        [135.9],\n",
       "        [177.3],\n",
       "        [180.9],\n",
       "        [162.9],\n",
       "        [162. ],\n",
       "        [160.2],\n",
       "        [159.3],\n",
       "        [162.9],\n",
       "        [167.4],\n",
       "        [167.4],\n",
       "        [164.7],\n",
       "        [163.8],\n",
       "        [175.5],\n",
       "        [217.8],\n",
       "        [249.3],\n",
       "        [249.3],\n",
       "        [220.5],\n",
       "        [212.4],\n",
       "        [207. ],\n",
       "        [186.3],\n",
       "        [164.7],\n",
       "        [153.9],\n",
       "        [148.5],\n",
       "        [145.8],\n",
       "        [153. ],\n",
       "        [162.9],\n",
       "        [170.1],\n",
       "        [171. ],\n",
       "        [177.3],\n",
       "        [183.6],\n",
       "        [185.4],\n",
       "        [187.2],\n",
       "        [253.8],\n",
       "        [284.4],\n",
       "        [258.3],\n",
       "        [210.6],\n",
       "        [193.5],\n",
       "        [170.1],\n",
       "        [143.1],\n",
       "        [131.4],\n",
       "        [149.4],\n",
       "        [190.8],\n",
       "        [206.1],\n",
       "        [216.9],\n",
       "        [216.9],\n",
       "        [195.3],\n",
       "        [208.8],\n",
       "        [225.9],\n",
       "        [208.8],\n",
       "        [189. ],\n",
       "        [179.1],\n",
       "        [155.7],\n",
       "        [169.2],\n",
       "        [202.5],\n",
       "        [217.8],\n",
       "        [226.8],\n",
       "        [227.7],\n",
       "        [229.5],\n",
       "        [226.8],\n",
       "        [225. ],\n",
       "        [229.5],\n",
       "        [219.6],\n",
       "        [210.6],\n",
       "        [200.7],\n",
       "        [193.5],\n",
       "        [186.3],\n",
       "        [174.6],\n",
       "        [171.9],\n",
       "        [171.9],\n",
       "        [169.2],\n",
       "        [168.3],\n",
       "        [166.5],\n",
       "        [166.5],\n",
       "        [171. ],\n",
       "        [172.8],\n",
       "        [169.2],\n",
       "        [174.6],\n",
       "        [171. ],\n",
       "        [165.6],\n",
       "        [164.7],\n",
       "        [158.4],\n",
       "        [160.2],\n",
       "        [153. ],\n",
       "        [145.8],\n",
       "        [147.6],\n",
       "        [152.1],\n",
       "        [160.2],\n",
       "        [216.9],\n",
       "        [240.3],\n",
       "        [264.6],\n",
       "        [277.2],\n",
       "        [263.7],\n",
       "        [231.3],\n",
       "        [194.4],\n",
       "        [178.2],\n",
       "        [166.5],\n",
       "        [145.8],\n",
       "        [126. ],\n",
       "        [120.6],\n",
       "        [130.5],\n",
       "        [142.2],\n",
       "        [155.7],\n",
       "        [160.2],\n",
       "        [179.1],\n",
       "        [192.6],\n",
       "        [183.6],\n",
       "        [177.3],\n",
       "        [176.4],\n",
       "        [186.3],\n",
       "        [189. ],\n",
       "        [186.3],\n",
       "        [173.7],\n",
       "        [174.6],\n",
       "        [160.2],\n",
       "        [171. ],\n",
       "        [164.7],\n",
       "        [161.1],\n",
       "        [158.4],\n",
       "        [162.9],\n",
       "        [158.4],\n",
       "        [160.2],\n",
       "        [170.1],\n",
       "        [174.6],\n",
       "        [167.4],\n",
       "        [210.6],\n",
       "        [264.6],\n",
       "        [270.9],\n",
       "        [245.7],\n",
       "        [202.5],\n",
       "        [175.5],\n",
       "        [151.2],\n",
       "        [135.9],\n",
       "        [136.8],\n",
       "        [161.1],\n",
       "        [183.6]]),\n",
       " array([[136.96277 ],\n",
       "        [131.6301  ],\n",
       "        [127.866455],\n",
       "        [125.68194 ],\n",
       "        [135.41495 ],\n",
       "        [141.37004 ],\n",
       "        [142.10957 ],\n",
       "        [167.35675 ],\n",
       "        [188.42747 ],\n",
       "        [200.5055  ],\n",
       "        [221.04532 ],\n",
       "        [226.91386 ],\n",
       "        [205.88115 ],\n",
       "        [202.01067 ],\n",
       "        [199.71132 ],\n",
       "        [177.78775 ],\n",
       "        [143.67535 ],\n",
       "        [148.87674 ],\n",
       "        [162.84308 ],\n",
       "        [156.5797  ],\n",
       "        [143.67535 ],\n",
       "        [136.16922 ],\n",
       "        [148.87674 ],\n",
       "        [148.87674 ],\n",
       "        [145.27153 ],\n",
       "        [151.98685 ],\n",
       "        [147.91882 ],\n",
       "        [143.67535 ],\n",
       "        [150.8687  ],\n",
       "        [146.07379 ],\n",
       "        [144.47333 ],\n",
       "        [151.98685 ],\n",
       "        [164.97902 ],\n",
       "        [169.84099 ],\n",
       "        [166.19255 ],\n",
       "        [223.97827 ],\n",
       "        [292.40198 ],\n",
       "        [307.5482  ],\n",
       "        [277.3129  ],\n",
       "        [223.97827 ],\n",
       "        [174.30983 ],\n",
       "        [146.9731  ],\n",
       "        [136.96277 ],\n",
       "        [164.97902 ],\n",
       "        [207.42624 ],\n",
       "        [227.64818 ],\n",
       "        [240.8828  ],\n",
       "        [237.93695 ],\n",
       "        [234.9936  ],\n",
       "        [216.54651 ],\n",
       "        [228.38266 ],\n",
       "        [226.91386 ],\n",
       "        [221.04532 ],\n",
       "        [199.71132 ],\n",
       "        [182.11516 ],\n",
       "        [177.78775 ],\n",
       "        [193.35692 ],\n",
       "        [196.59749 ],\n",
       "        [195.81311 ],\n",
       "        [202.77325 ],\n",
       "        [208.94005 ],\n",
       "        [161.4116  ],\n",
       "        [141.37004 ],\n",
       "        [151.98685 ],\n",
       "        [153.15314 ],\n",
       "        [162.84308 ],\n",
       "        [177.08276 ],\n",
       "        [181.22253 ],\n",
       "        [176.37859 ],\n",
       "        [177.08276 ],\n",
       "        [172.7399  ],\n",
       "        [171.98386 ],\n",
       "        [174.99304 ],\n",
       "        [171.98386 ],\n",
       "        [166.19255 ],\n",
       "        [162.84308 ],\n",
       "        [141.37004 ],\n",
       "        [160.62723 ],\n",
       "        [144.47334 ],\n",
       "        [142.8883  ],\n",
       "        [147.91882 ],\n",
       "        [149.87144 ],\n",
       "        [144.47334 ],\n",
       "        [143.67535 ],\n",
       "        [154.35515 ],\n",
       "        [153.15314 ],\n",
       "        [196.59749 ],\n",
       "        [232.78784 ],\n",
       "        [215.03358 ],\n",
       "        [207.42624 ],\n",
       "        [168.55676 ],\n",
       "        [158.7389  ],\n",
       "        [162.84308 ],\n",
       "        [164.29755 ],\n",
       "        [181.22253 ],\n",
       "        [203.5471  ],\n",
       "        [221.77829 ],\n",
       "        [223.24478 ],\n",
       "        [204.32346 ],\n",
       "        [176.37859 ],\n",
       "        [161.4116  ],\n",
       "        [143.67535 ],\n",
       "        [139.89865 ],\n",
       "        [144.47334 ],\n",
       "        [159.72899 ],\n",
       "        [168.55676 ],\n",
       "        [183.9114  ],\n",
       "        [215.78996 ],\n",
       "        [226.91386 ],\n",
       "        [226.91386 ],\n",
       "        [232.78784 ],\n",
       "        [237.20085 ],\n",
       "        [237.93695 ],\n",
       "        [224.71193 ],\n",
       "        [215.03358 ],\n",
       "        [210.4757  ],\n",
       "        [205.88115 ],\n",
       "        [189.2735  ],\n",
       "        [177.78775 ],\n",
       "        [182.11516 ],\n",
       "        [186.6528  ],\n",
       "        [174.30983 ],\n",
       "        [169.84099 ],\n",
       "        [183.00926 ],\n",
       "        [167.94911 ],\n",
       "        [159.72899 ],\n",
       "        [162.1281  ],\n",
       "        [159.72899 ],\n",
       "        [164.29755 ],\n",
       "        [166.77457 ],\n",
       "        [158.7389  ],\n",
       "        [188.42747 ],\n",
       "        [224.71193 ],\n",
       "        [221.77829 ],\n",
       "        [203.5471  ],\n",
       "        [191.68387 ],\n",
       "        [186.6528  ],\n",
       "        [178.54095 ],\n",
       "        [168.55676 ],\n",
       "        [196.59749 ],\n",
       "        [247.52016 ],\n",
       "        [272.79758 ],\n",
       "        [281.83347 ],\n",
       "        [275.05457 ],\n",
       "        [268.2877  ],\n",
       "        [257.87003 ],\n",
       "        [250.47417 ],\n",
       "        [236.46497 ],\n",
       "        [217.30322 ],\n",
       "        [199.71132 ],\n",
       "        [194.9996  ],\n",
       "        [186.6528  ],\n",
       "        [177.08276 ],\n",
       "        [191.68387 ],\n",
       "        [183.00926 ],\n",
       "        [183.00926 ],\n",
       "        [189.2735  ],\n",
       "        [199.71132 ],\n",
       "        [198.13559 ],\n",
       "        [200.5055  ],\n",
       "        [223.97827 ],\n",
       "        [235.72922 ],\n",
       "        [240.14609 ],\n",
       "        [216.54651 ],\n",
       "        [195.81311 ],\n",
       "        [174.30983 ],\n",
       "        [174.99304 ],\n",
       "        [166.77457 ],\n",
       "        [154.35515 ],\n",
       "        [151.98685 ],\n",
       "        [146.07379 ],\n",
       "        [144.47334 ],\n",
       "        [147.91882 ],\n",
       "        [146.07379 ],\n",
       "        [146.9731  ],\n",
       "        [148.87674 ],\n",
       "        [166.77457 ],\n",
       "        [154.35515 ],\n",
       "        [155.50134 ],\n",
       "        [203.5471  ],\n",
       "        [228.38266 ],\n",
       "        [238.67314 ],\n",
       "        [217.30322 ],\n",
       "        [198.1356  ],\n",
       "        [175.67958 ],\n",
       "        [143.67535 ],\n",
       "        [137.74208 ],\n",
       "        [131.6301  ],\n",
       "        [148.87674 ],\n",
       "        [165.59457 ],\n",
       "        [179.37303 ],\n",
       "        [172.7399  ],\n",
       "        [150.8687  ],\n",
       "        [167.94911 ],\n",
       "        [169.84099 ],\n",
       "        [170.53696 ],\n",
       "        [190.89178 ],\n",
       "        [229.84904 ],\n",
       "        [240.8828  ],\n",
       "        [231.31813 ],\n",
       "        [263.7977  ],\n",
       "        [281.07965 ],\n",
       "        [263.05618 ],\n",
       "        [244.56863 ],\n",
       "        [233.52295 ],\n",
       "        [213.52138 ],\n",
       "        [184.81378 ],\n",
       "        [158.7389  ],\n",
       "        [147.91882 ],\n",
       "        [160.62723 ],\n",
       "        [164.29755 ],\n",
       "        [136.96277 ],\n",
       "        [133.13254 ],\n",
       "        [134.67036 ],\n",
       "        [138.47583 ],\n",
       "        [140.61203 ],\n",
       "        [141.37004 ],\n",
       "        [142.10957 ],\n",
       "        [146.07379 ],\n",
       "        [146.9731  ],\n",
       "        [149.87144 ],\n",
       "        [142.10957 ],\n",
       "        [142.10957 ],\n",
       "        [146.07379 ],\n",
       "        [155.50134 ],\n",
       "        [147.91882 ],\n",
       "        [153.15314 ],\n",
       "        [208.94005 ],\n",
       "        [240.14609 ],\n",
       "        [241.61964 ],\n",
       "        [233.52295 ],\n",
       "        [198.1356  ],\n",
       "        [149.87144 ],\n",
       "        [130.8792  ],\n",
       "        [117.87894 ],\n",
       "        [158.7389  ],\n",
       "        [200.5055  ],\n",
       "        [215.03358 ],\n",
       "        [205.09999 ],\n",
       "        [174.30983 ],\n",
       "        [183.9114  ],\n",
       "        [194.9996  ],\n",
       "        [220.31248 ],\n",
       "        [243.09381 ],\n",
       "        [246.0441  ],\n",
       "        [249.73544 ],\n",
       "        [251.95209 ],\n",
       "        [227.64818 ],\n",
       "        [206.66267 ],\n",
       "        [183.9114  ],\n",
       "        [191.68387 ],\n",
       "        [167.35675 ],\n",
       "        [127.866455],\n",
       "        [130.1285  ],\n",
       "        [136.96277 ],\n",
       "        [141.37004 ],\n",
       "        [153.15314 ],\n",
       "        [169.18839 ],\n",
       "        [176.37859 ],\n",
       "        [186.6528  ],\n",
       "        [186.6528  ],\n",
       "        [185.72192 ],\n",
       "        [188.42747 ],\n",
       "        [186.6528  ],\n",
       "        [179.37305 ],\n",
       "        [177.08276 ],\n",
       "        [172.7399  ],\n",
       "        [166.77457 ],\n",
       "        [160.62723 ],\n",
       "        [159.72899 ],\n",
       "        [160.62723 ],\n",
       "        [154.35515 ],\n",
       "        [163.55576 ],\n",
       "        [151.98685 ],\n",
       "        [144.47334 ],\n",
       "        [171.98386 ],\n",
       "        [223.24478 ],\n",
       "        [242.35664 ],\n",
       "        [240.14609 ],\n",
       "        [213.52138 ],\n",
       "        [178.54095 ],\n",
       "        [150.8687  ],\n",
       "        [120.889   ],\n",
       "        [125.68194 ],\n",
       "        [143.67535 ],\n",
       "        [181.22253 ],\n",
       "        [199.71133 ],\n",
       "        [180.2964  ],\n",
       "        [146.9731  ],\n",
       "        [138.47583 ],\n",
       "        [130.8792  ],\n",
       "        [142.8883  ],\n",
       "        [138.47583 ],\n",
       "        [147.91882 ],\n",
       "        [171.98386 ],\n",
       "        [199.71132 ],\n",
       "        [217.30322 ],\n",
       "        [207.42624 ],\n",
       "        [188.42747 ],\n",
       "        [185.72192 ],\n",
       "        [237.93695 ],\n",
       "        [246.0441  ],\n",
       "        [218.0601  ],\n",
       "        [204.32346 ],\n",
       "        [189.2735  ],\n",
       "        [171.23871 ],\n",
       "        [168.55676 ],\n",
       "        [172.7399  ],\n",
       "        [178.54095 ],\n",
       "        [174.99304 ],\n",
       "        [175.67958 ],\n",
       "        [173.53398 ],\n",
       "        [169.18839 ],\n",
       "        [169.18839 ],\n",
       "        [169.18839 ],\n",
       "        [173.53398 ],\n",
       "        [168.55676 ],\n",
       "        [167.35675 ],\n",
       "        [165.59457 ],\n",
       "        [172.7399  ],\n",
       "        [179.37305 ],\n",
       "        [171.98386 ],\n",
       "        [169.18839 ],\n",
       "        [167.94911 ],\n",
       "        [174.30983 ],\n",
       "        [236.46497 ],\n",
       "        [282.58743 ],\n",
       "        [291.64615 ],\n",
       "        [265.28412 ],\n",
       "        [252.6913  ],\n",
       "        [223.24478 ],\n",
       "        [192.51044 ],\n",
       "        [190.09624 ],\n",
       "        [174.99304 ],\n",
       "        [155.50134 ],\n",
       "        [155.50134 ],\n",
       "        [146.07379 ],\n",
       "        [134.67036 ],\n",
       "        [157.66203 ],\n",
       "        [215.03358 ],\n",
       "        [256.38962 ],\n",
       "        [274.3021  ],\n",
       "        [294.67032 ],\n",
       "        [284.09576 ],\n",
       "        [239.40952 ],\n",
       "        [213.52138 ],\n",
       "        [215.78996 ],\n",
       "        [227.64818 ],\n",
       "        [232.0529  ],\n",
       "        [216.54651 ],\n",
       "        [219.5744  ],\n",
       "        [219.5744  ],\n",
       "        [221.77829 ],\n",
       "        [225.44574 ],\n",
       "        [228.38266 ],\n",
       "        [235.72922 ],\n",
       "        [226.17973 ],\n",
       "        [211.24379 ],\n",
       "        [204.32346 ],\n",
       "        [193.35692 ],\n",
       "        [207.42624 ],\n",
       "        [218.81718 ],\n",
       "        [222.51144 ],\n",
       "        [223.97827 ],\n",
       "        [223.97827 ],\n",
       "        [217.30322 ],\n",
       "        [210.4757  ],\n",
       "        [194.9996  ],\n",
       "        [197.36288 ],\n",
       "        [185.72192 ],\n",
       "        [165.59457 ],\n",
       "        [191.68387 ],\n",
       "        [254.90984 ],\n",
       "        [265.28412 ],\n",
       "        [247.52016 ],\n",
       "        [214.2774  ],\n",
       "        [179.37305 ],\n",
       "        [157.66203 ],\n",
       "        [137.74208 ],\n",
       "        [127.13044 ],\n",
       "        [128.62383 ],\n",
       "        [119.62324 ],\n",
       "        [122.889336],\n",
       "        [154.35515 ],\n",
       "        [169.84099 ],\n",
       "        [160.62723 ],\n",
       "        [180.2964  ],\n",
       "        [205.09999 ],\n",
       "        [207.42624 ],\n",
       "        [217.30322 ],\n",
       "        [212.00986 ],\n",
       "        [187.57632 ],\n",
       "        [171.98386 ],\n",
       "        [178.54095 ],\n",
       "        [183.00926 ],\n",
       "        [184.81378 ],\n",
       "        [183.9114  ],\n",
       "        [181.22253 ],\n",
       "        [174.99304 ],\n",
       "        [174.30983 ],\n",
       "        [163.55576 ],\n",
       "        [162.84308 ],\n",
       "        [184.81378 ],\n",
       "        [183.00926 ],\n",
       "        [170.53696 ],\n",
       "        [163.55576 ],\n",
       "        [162.1281  ],\n",
       "        [160.62723 ],\n",
       "        [164.29755 ],\n",
       "        [162.1281  ],\n",
       "        [156.5797  ],\n",
       "        [156.5797  ],\n",
       "        [151.98685 ],\n",
       "        [155.50134 ],\n",
       "        [154.35515 ],\n",
       "        [155.50134 ],\n",
       "        [164.29755 ],\n",
       "        [166.19255 ],\n",
       "        [167.94911 ],\n",
       "        [211.24379 ],\n",
       "        [270.542   ],\n",
       "        [287.11417 ],\n",
       "        [266.03476 ],\n",
       "        [217.30322 ],\n",
       "        [171.98386 ],\n",
       "        [146.9731  ],\n",
       "        [121.53419 ],\n",
       "        [115.89295 ],\n",
       "        [112.85222 ],\n",
       "        [114.04878 ],\n",
       "        [111.296234],\n",
       "        [126.40609 ],\n",
       "        [175.67958 ],\n",
       "        [218.0601  ],\n",
       "        [251.95209 ],\n",
       "        [268.2877  ],\n",
       "        [254.90984 ],\n",
       "        [232.0529  ],\n",
       "        [242.35664 ],\n",
       "        [229.84904 ],\n",
       "        [197.36288 ],\n",
       "        [183.00926 ],\n",
       "        [183.00926 ],\n",
       "        [183.9114  ],\n",
       "        [177.78775 ],\n",
       "        [162.1281  ],\n",
       "        [176.37859 ],\n",
       "        [190.89178 ],\n",
       "        [206.66267 ],\n",
       "        [232.0529  ],\n",
       "        [244.56863 ],\n",
       "        [234.25821 ],\n",
       "        [229.1173  ],\n",
       "        [201.25435 ],\n",
       "        [202.01067 ],\n",
       "        [191.68387 ],\n",
       "        [181.22253 ],\n",
       "        [175.67958 ],\n",
       "        [183.9114  ],\n",
       "        [176.37859 ],\n",
       "        [174.30983 ],\n",
       "        [176.37859 ],\n",
       "        [175.67958 ],\n",
       "        [172.7399  ],\n",
       "        [172.7399  ],\n",
       "        [182.11516 ],\n",
       "        [182.11516 ],\n",
       "        [173.53398 ],\n",
       "        [175.67958 ],\n",
       "        [183.9114  ],\n",
       "        [170.53696 ],\n",
       "        [192.51044 ],\n",
       "        [250.47417 ],\n",
       "        [283.34155 ],\n",
       "        [287.86914 ],\n",
       "        [282.58743 ],\n",
       "        [241.61964 ],\n",
       "        [208.94005 ],\n",
       "        [171.98386 ],\n",
       "        [158.7389  ],\n",
       "        [156.5797  ],\n",
       "        [146.07379 ],\n",
       "        [141.37004 ],\n",
       "        [144.47334 ],\n",
       "        [158.7389  ],\n",
       "        [214.2774  ],\n",
       "        [266.03476 ],\n",
       "        [287.86914 ],\n",
       "        [286.35938 ],\n",
       "        [278.06595 ],\n",
       "        [264.53937 ],\n",
       "        [244.56863 ],\n",
       "        [240.8828  ],\n",
       "        [231.31813 ],\n",
       "        [207.42624 ],\n",
       "        [189.2735  ],\n",
       "        [177.78775 ],\n",
       "        [186.6528  ],\n",
       "        [194.18631 ],\n",
       "        [186.6528  ],\n",
       "        [182.11516 ],\n",
       "        [184.81378 ],\n",
       "        [177.78775 ],\n",
       "        [176.37859 ],\n",
       "        [180.2964  ],\n",
       "        [177.08276 ],\n",
       "        [183.9114  ],\n",
       "        [172.7399  ],\n",
       "        [167.35675 ],\n",
       "        [170.53696 ],\n",
       "        [169.18839 ],\n",
       "        [167.94911 ],\n",
       "        [168.55676 ],\n",
       "        [175.67958 ],\n",
       "        [184.81378 ],\n",
       "        [245.30629 ],\n",
       "        [267.53656 ],\n",
       "        [256.38962 ],\n",
       "        [217.30322 ],\n",
       "        [189.2735  ],\n",
       "        [166.77457 ],\n",
       "        [154.35515 ],\n",
       "        [147.91882 ],\n",
       "        [164.97902 ],\n",
       "        [199.71132 ],\n",
       "        [233.52295 ],\n",
       "        [241.61964 ],\n",
       "        [237.20085 ],\n",
       "        [240.14609 ],\n",
       "        [225.44574 ],\n",
       "        [197.36288 ],\n",
       "        [166.77457 ],\n",
       "        [157.66203 ],\n",
       "        [149.87144 ],\n",
       "        [142.8883  ],\n",
       "        [140.61203 ],\n",
       "        [177.78775 ],\n",
       "        [181.22253 ],\n",
       "        [166.77457 ],\n",
       "        [166.19255 ],\n",
       "        [164.97902 ],\n",
       "        [164.29755 ],\n",
       "        [166.77457 ],\n",
       "        [169.84099 ],\n",
       "        [169.84099 ],\n",
       "        [167.94911 ],\n",
       "        [167.35675 ],\n",
       "        [176.37859 ],\n",
       "        [214.2774  ],\n",
       "        [240.14609 ],\n",
       "        [240.14609 ],\n",
       "        [216.54651 ],\n",
       "        [209.70778 ],\n",
       "        [205.09999 ],\n",
       "        [186.6528  ],\n",
       "        [167.94911 ],\n",
       "        [159.72899 ],\n",
       "        [153.15314 ],\n",
       "        [149.87144 ],\n",
       "        [158.7389  ],\n",
       "        [166.77457 ],\n",
       "        [171.98386 ],\n",
       "        [172.7399  ],\n",
       "        [177.78775 ],\n",
       "        [183.9114  ],\n",
       "        [185.72192 ],\n",
       "        [187.57632 ],\n",
       "        [243.83113 ],\n",
       "        [269.03897 ],\n",
       "        [247.52016 ],\n",
       "        [208.18077 ],\n",
       "        [193.35692 ],\n",
       "        [171.98386 ],\n",
       "        [146.9731  ],\n",
       "        [136.96277 ],\n",
       "        [154.35515 ],\n",
       "        [190.89178 ],\n",
       "        [204.32346 ],\n",
       "        [213.52138 ],\n",
       "        [213.52138 ],\n",
       "        [194.9996  ],\n",
       "        [206.66267 ],\n",
       "        [221.04532 ],\n",
       "        [206.66267 ],\n",
       "        [189.2735  ],\n",
       "        [179.37305 ],\n",
       "        [161.4116  ],\n",
       "        [171.23871 ],\n",
       "        [201.25435 ],\n",
       "        [214.2774  ],\n",
       "        [221.77829 ],\n",
       "        [222.51144 ],\n",
       "        [223.97827 ],\n",
       "        [221.77829 ],\n",
       "        [220.31248 ],\n",
       "        [223.97827 ],\n",
       "        [215.78996 ],\n",
       "        [208.18077 ],\n",
       "        [199.71132 ],\n",
       "        [193.35692 ],\n",
       "        [186.6528  ],\n",
       "        [175.67958 ],\n",
       "        [173.53398 ],\n",
       "        [173.53398 ],\n",
       "        [171.23871 ],\n",
       "        [170.53696 ],\n",
       "        [169.18839 ],\n",
       "        [169.18839 ],\n",
       "        [172.7399  ],\n",
       "        [174.30983 ],\n",
       "        [171.23871 ],\n",
       "        [175.67958 ],\n",
       "        [172.7399  ],\n",
       "        [168.55676 ],\n",
       "        [167.94911 ],\n",
       "        [163.55576 ],\n",
       "        [164.97902 ],\n",
       "        [158.7389  ],\n",
       "        [149.87144 ],\n",
       "        [151.98685 ],\n",
       "        [157.66203 ],\n",
       "        [164.97902 ],\n",
       "        [213.52138 ],\n",
       "        [232.78784 ],\n",
       "        [252.6913  ],\n",
       "        [263.05618 ],\n",
       "        [251.95209 ],\n",
       "        [225.44574 ],\n",
       "        [194.18631 ],\n",
       "        [178.54095 ],\n",
       "        [169.18839 ],\n",
       "        [149.87144 ],\n",
       "        [132.38121 ],\n",
       "        [127.866455],\n",
       "        [136.16922 ],\n",
       "        [146.07379 ],\n",
       "        [161.4116  ],\n",
       "        [164.97902 ],\n",
       "        [179.37303 ],\n",
       "        [192.51044 ],\n",
       "        [183.9114  ],\n",
       "        [177.78775 ],\n",
       "        [177.08276 ],\n",
       "        [186.6528  ],\n",
       "        [189.2735  ],\n",
       "        [186.6528  ],\n",
       "        [174.99304 ],\n",
       "        [175.67958 ],\n",
       "        [164.97902 ],\n",
       "        [172.7399  ],\n",
       "        [167.94911 ],\n",
       "        [165.59457 ],\n",
       "        [163.55576 ],\n",
       "        [166.77457 ],\n",
       "        [163.55576 ],\n",
       "        [164.97902 ],\n",
       "        [171.98386 ],\n",
       "        [175.67958 ],\n",
       "        [169.84099 ],\n",
       "        [208.18077 ],\n",
       "        [252.6913  ],\n",
       "        [257.87003 ],\n",
       "        [237.20085 ],\n",
       "        [201.25435 ],\n",
       "        [176.37859 ],\n",
       "        [156.5797  ],\n",
       "        [140.61203 ],\n",
       "        [141.37004 ],\n",
       "        [165.59457 ]], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "from keras.models import load_model\n",
    "model = load_model('t2_lstm_cgm.h5')\n",
    "\n",
    "predict_by_model(model, data, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
